{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b8db711-1e28-4c8c-825d-594f03395d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05428d56-c073-4267-8190-b57703c7c092",
   "metadata": {
    "executionInfo": {
     "elapsed": 624,
     "status": "ok",
     "timestamp": 1717533895277,
     "user": {
      "displayName": "Matthias Huebscher",
      "userId": "17596753721121631212"
     },
     "user_tz": -120
    },
    "id": "05428d56-c073-4267-8190-b57703c7c092"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import ms2_model\n",
    "from ms2_model import Net256\n",
    "from ms2_dataset import EmbedVec256Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b242b71b-7d21-46b2-a66d-c67f96560e89",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1717533895278,
     "user": {
      "displayName": "Matthias Huebscher",
      "userId": "17596753721121631212"
     },
     "user_tz": -120
    },
    "id": "b242b71b-7d21-46b2-a66d-c67f96560e89",
    "outputId": "bead82cc-42c8-4c6c-f60d-9f156ec59f92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x148f7f867250>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(764)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "LkpeVfVuM4-B",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1717533895278,
     "user": {
      "displayName": "Matthias Huebscher",
      "userId": "17596753721121631212"
     },
     "user_tz": -120
    },
    "id": "LkpeVfVuM4-B"
   },
   "outputs": [],
   "source": [
    "def balance_train_data(df, random_state):\n",
    "  df_grp = df.groupby([\"Metadata_MoA\"])[\"Metadata_Compound\"].count().reset_index(name=\"count\")\n",
    "  mean_count = int(df_grp.drop(df_grp[df_grp[\"Metadata_MoA\"] == \"DMSO\"].index)[\"count\"].mean().round())\n",
    "\n",
    "  df_dmso = df[df[\"Metadata_MoA\"] == \"DMSO\"].sample(n=mean_count, random_state=random_state)\n",
    "  df_other = df.drop(df[df[\"Metadata_MoA\"] == \"DMSO\"].index)\n",
    "\n",
    "  df_all = pd.concat([df_other, df_dmso], axis=0)\n",
    "  return df_all.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fbc8210-c3c2-437b-9807-dbe7873b524d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1717533895809,
     "user": {
      "displayName": "Matthias Huebscher",
      "userId": "17596753721121631212"
     },
     "user_tz": -120
    },
    "id": "5fbc8210-c3c2-437b-9807-dbe7873b524d",
    "outputId": "5de211ab-2387-4cff-99a4-d2b7ddf24724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"~/siads696/data\"\n",
    "\n",
    "random_state = 764\n",
    "cv_splits = 5\n",
    "\n",
    "learning_rate = 0.001\n",
    "n_epochs = 14\n",
    "batch_size = 32\n",
    "chunk_print = 10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "# if device == \"cuda:0\":\n",
    "#     torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72799052-bf62-4538-ad3f-e4cbbcc6745b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2348,
     "status": "ok",
     "timestamp": 1717533898151,
     "user": {
      "displayName": "Matthias Huebscher",
      "userId": "17596753721121631212"
     },
     "user_tz": -120
    },
    "id": "72799052-bf62-4538-ad3f-e4cbbcc6745b",
    "outputId": "3b0f6f89-1eba-4099-cf7c-cd6261fc3db2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding vector dataset shape: (13200, 265)\n",
      "Embedding vectors MoA assigned: 6160\n"
     ]
    }
   ],
   "source": [
    "df_data = pd.read_parquet(os.path.join(data_dir, \"bbbc021_image_embed_batchcorr_256.parquet\"))\n",
    "# df_data = pd.read_parquet(os.path.join(data_dir, \"well_grouped_256.parquet\"))\n",
    "\n",
    "print(f\"Embedding vector dataset shape: {df_data.shape}\")\n",
    "print(f\"Embedding vectors MoA assigned: {df_data[~df_data['Metadata_MoA'].isnull()].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04e96f35-802d-41cc-bab9-7e3c9e94f6e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1717533898152,
     "user": {
      "displayName": "Matthias Huebscher",
      "userId": "17596753721121631212"
     },
     "user_tz": -120
    },
    "id": "13139647-a46e-446b-88f3-30d0df401def",
    "outputId": "fbb8fd21-98a1-4334-dfd9-015072402859"
   },
   "outputs": [],
   "source": [
    "df_train_test = pd.read_csv(os.path.join(data_dir, \"compound_moas_trainVtest.csv\"))\n",
    "df_train = df_train_test[~df_train_test[\"in_testset\"]]\n",
    "df_test = df_train_test[df_train_test[\"in_testset\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cecbf00f-a427-4458-a5c5-31855b5d7092",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1717533898152,
     "user": {
      "displayName": "Matthias Huebscher",
      "userId": "17596753721121631212"
     },
     "user_tz": -120
    },
    "id": "13139647-a46e-446b-88f3-30d0df401def",
    "outputId": "fbb8fd21-98a1-4334-dfd9-015072402859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/test set shape: (39, 4)\n",
      "Training set shape: (29, 4)\n",
      "Test set shape: (10, 4)\n",
      "MoA in training set:\n",
      " ['Actin disruptors', 'Aurora kinase inhibitors', 'Cholesterol-lowering', 'DMSO', 'DNA damage', 'DNA replication', 'Eg5 inhibitors', 'Epithelial', 'Kinase inhibitors', 'Microtubule destabilizers', 'Microtubule stabilizers', 'Protein degradation', 'Protein synthesis']\n",
      "MoA in test set:\n",
      " ['Actin disruptors', 'Aurora kinase inhibitors', 'DNA damage', 'DNA replication', 'Epithelial', 'Kinase inhibitors', 'Microtubule destabilizers', 'Microtubule stabilizers', 'Protein degradation', 'Protein synthesis']\n",
      "Compounds in training set:\n",
      " ['cytochalasin B', 'cytochalasin D', 'AZ-A', 'AZ258', 'mevinolin/lovastatin', 'simvastatin', 'DMSO', 'chlorambucil', 'cisplatin', 'etoposide', 'camptothecin', 'floxuridine', 'methotrexate', 'AZ-C', 'AZ138', 'AZ-J', 'AZ-U', 'PD-169316', 'alsterpaullone', 'colchicine', 'demecolcine', 'nocodazole', 'docetaxel', 'epothilone B', 'ALLN', 'MG-132', 'lactacystin', 'anisomycin', 'cyclohexamide']\n",
      "Compounds in test set:\n",
      " ['latrunculin B', 'AZ841', 'mitomycin C', 'mitoxantrone', 'PP-2', 'bryostatin', 'vincristine', 'taxol', 'proteasome inhibitor I', 'emetine']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train/test set shape: {df_train_test.shape}\")\n",
    "print(f\"Training set shape: {df_train.shape}\")\n",
    "print(f\"Test set shape: {df_test.shape}\")\n",
    "print(f\"MoA in training set:\\n {df_train['MoA'].unique().tolist()}\")\n",
    "print(f\"MoA in test set:\\n {df_test['MoA'].unique().tolist()}\")\n",
    "print(f\"Compounds in training set:\\n {df_train['Compound'].unique().tolist()}\")\n",
    "print(f\"Compounds in test set:\\n {df_test['Compound'].unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc042686-cf10-4c7a-b191-00879043781f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1717533898152,
     "user": {
      "displayName": "Matthias Huebscher",
      "userId": "17596753721121631212"
     },
     "user_tz": -120
    },
    "id": "94b71196-8df5-482a-aca2-0eaa9a549fe2",
    "outputId": "eaeed301-7dcb-4ed5-895b-8483d7d81930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (3944, 269)\n",
      "Training data balanced shape: (2843, 269)\n"
     ]
    }
   ],
   "source": [
    "data_cols = [c for c in df_data.columns if c.startswith(\"PC\")]\n",
    "\n",
    "df_data_train = df_data.merge(df_train, left_on=\"Metadata_Compound\", right_on=\"Compound\", how=\"inner\")\n",
    "print(f\"Training data shape: {df_data_train.shape}\")\n",
    "df_data_train = balance_train_data(df_data_train, random_state)\n",
    "print(f\"Training data balanced shape: {df_data_train.shape}\")\n",
    "# df_data_train = pd.concat([df_data_train, df_data_train], ignore_index=True)\n",
    "\n",
    "# data_matrix = df_data_train[data_cols]\n",
    "df_data_test = df_data.merge(df_test, left_on=\"Metadata_Compound\", right_on=\"Compound\", how=\"inner\")\n",
    "# data_matrix = df_data_test[data_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b2376bf-5472-47f5-987a-81dcf85a7efb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1717533898152,
     "user": {
      "displayName": "Matthias Huebscher",
      "userId": "17596753721121631212"
     },
     "user_tz": -120
    },
    "id": "94b71196-8df5-482a-aca2-0eaa9a549fe2",
    "outputId": "eaeed301-7dcb-4ed5-895b-8483d7d81930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (2216, 269)\n",
      "Total embedding vectors in training/test set: 5059\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test data shape: {df_data_test.shape}\")\n",
    "print(f\"Total embedding vectors in training/test set: {df_data_train.shape[0]+df_data_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ee8b2c4-1e21-482d-85eb-5f9e2169444e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1717533898152,
     "user": {
      "displayName": "Matthias Huebscher",
      "userId": "17596753721121631212"
     },
     "user_tz": -120
    },
    "id": "2e0f6851-a047-4999-8398-a1911b4b39c4",
    "outputId": "f177a88c-c9c9-4a9a-a0d5-fa2706751a26"
   },
   "outputs": [],
   "source": [
    "moa_list = df_data[~df_data[\"Metadata_MoA\"].isnull()].loc[:, \"Metadata_MoA\"].unique().tolist()\n",
    "moa_dict = {moa: idx for moa, idx in zip(moa_list, range(len(moa_list)))}\n",
    "n_classes = len(moa_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e81cc48-2585-4914-8710-4581c8b1703d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e498bfe-172c-4e6e-bf33-1e3ef3640934",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1717533898152,
     "user": {
      "displayName": "Matthias Huebscher",
      "userId": "17596753721121631212"
     },
     "user_tz": -120
    },
    "id": "2e0f6851-a047-4999-8398-a1911b4b39c4",
    "outputId": "f177a88c-c9c9-4a9a-a0d5-fa2706751a26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoA label dictionary:\n",
      "{'Protein degradation': 0, 'Kinase inhibitors': 1, 'Protein synthesis': 2, 'DNA replication': 3, 'DNA damage': 4, 'Microtubule destabilizers': 5, 'Actin disruptors': 6, 'Microtubule stabilizers': 7, 'Cholesterol-lowering': 8, 'Epithelial': 9, 'Eg5 inhibitors': 10, 'Aurora kinase inhibitors': 11, 'DMSO': 12}\n",
      "Number of classes: 13\n"
     ]
    }
   ],
   "source": [
    "print(f\"MoA label dictionary:\\n{moa_dict}\")\n",
    "print(f\"Number of classes: {n_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "842b796e-25e0-4004-90fb-1a14caa21dc3",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1717533898152,
     "user": {
      "displayName": "Matthias Huebscher",
      "userId": "17596753721121631212"
     },
     "user_tz": -120
    },
    "id": "842b796e-25e0-4004-90fb-1a14caa21dc3"
   },
   "outputs": [],
   "source": [
    "train_dataset = EmbedVec256Dataset(df_data_train, \"Metadata_MoA\", \"PC\", moa_dict)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = EmbedVec256Dataset(df_data_test, \"Metadata_MoA\", \"PC\", moa_dict)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31faebe4-57e1-426c-be2b-8c0e39b0b43e",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1717533898152,
     "user": {
      "displayName": "Matthias Huebscher",
      "userId": "17596753721121631212"
     },
     "user_tz": -120
    },
    "id": "31faebe4-57e1-426c-be2b-8c0e39b0b43e"
   },
   "outputs": [],
   "source": [
    "model = Net256(n_classes, 256, 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01a46a65-000d-4bb6-97a2-fa54584b7af0",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1717533898153,
     "user": {
      "displayName": "Matthias Huebscher",
      "userId": "17596753721121631212"
     },
     "user_tz": -120
    },
    "id": "01a46a65-000d-4bb6-97a2-fa54584b7af0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhuebsch/.conda/envs/ms2/lib/python3.12/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "# using cross entropy loss for multiclass classification\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# use Adam as optimizer for this NN\n",
    "optimizer = torch.optim.Adam(model.parameters(), foreach=True, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "94e537c9-3a2a-4d2d-b282-63eebd2fa4c7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10136,
     "status": "ok",
     "timestamp": 1717533908280,
     "user": {
      "displayName": "Matthias Huebscher",
      "userId": "17596753721121631212"
     },
     "user_tz": -120
    },
    "id": "94e537c9-3a2a-4d2d-b282-63eebd2fa4c7",
    "outputId": "9c512739-a197-4d7c-cace-7344d79e9331"
   },
   "outputs": [],
   "source": [
    "# print(\"Begin Training\")\n",
    "\n",
    "# for epoch in range(n_epochs):\n",
    "#     running_loss = 0.0\n",
    "#     loss, accuracy = ms2_model.train_model(model, optimizer, loss_func, train_dataloader)\n",
    "#     print(f\"Epoch {epoch+1}  Loss: {loss:>5f}  Accuracy: {accuracy:>5f}\")\n",
    "# print(\"Stop Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8ea465dc-688d-43ab-9cc2-51b96b9f2aca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 588,
     "status": "ok",
     "timestamp": 1717533908847,
     "user": {
      "displayName": "Matthias Huebscher",
      "userId": "17596753721121631212"
     },
     "user_tz": -120
    },
    "id": "8ea465dc-688d-43ab-9cc2-51b96b9f2aca",
    "outputId": "3854051e-e1b9-4634-ab1e-03a7f7f15263"
   },
   "outputs": [],
   "source": [
    "# y_label = df_data_test[\"Metadata_MoA\"].map(moa_dict).tolist()\n",
    "\n",
    "# avg_loss, yhat_label = ms2_model.test_model(model, loss_func, test_dataloader)\n",
    "\n",
    "# print(avg_loss)\n",
    "# print(accuracy_score(y_label, yhat_label))\n",
    "# print(f1_score(y_label, yhat_label, average=\"weighted\"))\n",
    "# print(precision_score(y_label, yhat_label, average=None))\n",
    "# print(recall_score(y_label, yhat_label, zero_division=np.nan, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "52c88b6f-a338-4e08-84d6-fe3d82708a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_params(param_dict):\n",
    "    params = list(param_dict.keys())\n",
    "    param_list = [param_dict[param] for param in params]\n",
    "    param_combi =  itertools.product(*param_list) \n",
    "    \n",
    "    return params, list(param_combi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "10868992-3ade-44b2-a830-fd837a317ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_kfold_crossval(cv_splits, dataset, random_state, parameters, verbose=True):\n",
    "    kfold = KFold(n_splits=cv_splits, shuffle=True, random_state=random_state)\n",
    "    cv_values = np.zeros((cv_splits, 4))\n",
    "    \n",
    "    learning_rate = parameters[0]\n",
    "    batch_size = parameters[1]\n",
    "    n_epochs = parameters[2]\n",
    "    \n",
    "    for fold ,(train_idx, valid_idx) in enumerate(kfold.split(np.arange(len(dataset)))):\n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "        train_dataloader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "        valid_dataloader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "    \n",
    "        model = Net256(n_classes).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), foreach=True, lr=learning_rate)\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "    \n",
    "        cv_fold_values = np.zeros((n_epochs, 4))\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            train_loss, train_acc = ms2_model.train_model(model, optimizer, loss_func, train_dataloader, device)\n",
    "            valid_loss, valid_acc = ms2_model.valid_model(model, loss_func, valid_dataloader, device)\n",
    "            tl = train_loss / len(train_dataloader.sampler)\n",
    "            ta = train_acc / len(train_dataloader.sampler)\n",
    "            vl = valid_loss / len(valid_dataloader.sampler)\n",
    "            va = valid_acc / len(valid_dataloader.sampler)\n",
    "            cv_fold_values[epoch,0] = tl\n",
    "            cv_fold_values[epoch,1] = ta\n",
    "            cv_fold_values[epoch,2] = vl\n",
    "            cv_fold_values[epoch,3] = va\n",
    "        cv_values[fold,0] = cv_fold_values[-1,0]\n",
    "        cv_values[fold,1] = cv_fold_values[-1,1]\n",
    "        cv_values[fold,2] = cv_fold_values[-1,2]\n",
    "        cv_values[fold,3] = cv_fold_values[-1,3]\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Fold {fold+1}: Train loss: {tl:>5f}  Train accuracy: {ta:>5f}  Valid loss: {vl:>5f}  Valid accuracy: {va:>5f}\")\n",
    "    \n",
    "    cv_mean_tl = cv_values[:,0].mean()\n",
    "    cv_std_tl = cv_values[:,0].std()\n",
    "    cv_mean_ta = cv_values[:,1].mean()\n",
    "    cv_std_ta = cv_values[:,1].std()\n",
    "    cv_mean_vl = cv_values[:,2].mean()\n",
    "    cv_std_vl = cv_values[:,2].std()\n",
    "    cv_mean_va = cv_values[:,3].mean()\n",
    "    cv_std_va = cv_values[:,3].std()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Training - loss mean: {cv_mean_tl:>5f}  loss std: {cv_std_tl:>5f}\")\n",
    "        print(f\"Training - accuracy mean: {cv_mean_ta:>5f}  accuracy std: {cv_std_ta:>5f}\")\n",
    "        print(f\"Validation - loss mean: {cv_mean_vl:>5f}  loss std: {cv_std_vl:>5f}\")\n",
    "        print(f\"Validation - accuracy mean: {cv_mean_va:>5f}  accuracy std: {cv_std_va:>5f}\")\n",
    "\n",
    "    return [cv_mean_tl, cv_std_tl, cv_mean_ta, cv_std_ta, cv_mean_vl, cv_std_vl, cv_mean_va, cv_std_va]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d10b97ea-6073-42eb-8b83-10445530f4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.0001  batch_size: 8  epochs: 12\n",
      "Fold 1: Train loss: 0.901042  Train accuracy: 0.798593  Valid loss: 0.910947  Valid accuracy: 0.778559\n",
      "Fold 2: Train loss: 0.934162  Train accuracy: 0.799033  Valid loss: 0.791910  Valid accuracy: 0.824253\n",
      "Fold 3: Train loss: 0.898099  Train accuracy: 0.802111  Valid loss: 0.872259  Valid accuracy: 0.785589\n",
      "Fold 4: Train loss: 0.923677  Train accuracy: 0.795604  Valid loss: 0.933004  Valid accuracy: 0.783451\n",
      "Fold 5: Train loss: 0.899785  Train accuracy: 0.806593  Valid loss: 0.852362  Valid accuracy: 0.804577\n",
      "Training - loss mean: 0.911353  loss std: 0.014751\n",
      "Training - accuracy mean: 0.800387  accuracy std: 0.003726\n",
      "Validation - loss mean: 0.872097  loss std: 0.049068\n",
      "Validation - accuracy mean: 0.795286  accuracy std: 0.016967\n",
      "CPU times: user 1min 57s, sys: 427 ms, total: 1min 57s\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_dict = {\"learning_rate\": [0.0001],\n",
    "             \"batch_size\": [16],\n",
    "             \"epochs\": [12]}\n",
    "\n",
    "parameters, combinations = enumerate_params(param_dict)\n",
    "\n",
    "gridsearch_records = list()\n",
    "value_cols = [\"trianing_loss mean\", \n",
    "              \"training_loss std\", \n",
    "              \"training_acc mean\", \n",
    "              \"training_acc std\", \n",
    "              \"validation_loss mean\", \n",
    "              \"validation_loss std\", \n",
    "              \"validaton_acc mean\", \n",
    "              \"validation_acc std\"]\n",
    "result_cols = parameters\n",
    "result_cols.extend(value_cols)\n",
    "\n",
    "for combination in combinations:\n",
    "    print(f\"learning rate: {combination[0]}  batch_size: {combination[1]}  epochs: {combination[2]}\")\n",
    "    grid_results = do_kfold_crossval(cv_splits, train_dataset, random_state, combination, verbose=True)\n",
    "    combi_results = list(combination)\n",
    "    combi_results.extend(grid_results)\n",
    "    gridsearch_records.append(tuple(combi_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "64381881-06f6-4a50-acb5-e06cd9a06cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>trianing_loss mean</th>\n",
       "      <th>training_loss std</th>\n",
       "      <th>training_acc mean</th>\n",
       "      <th>training_acc std</th>\n",
       "      <th>validation_loss mean</th>\n",
       "      <th>validation_loss std</th>\n",
       "      <th>validaton_acc mean</th>\n",
       "      <th>validation_acc std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.911353</td>\n",
       "      <td>0.014751</td>\n",
       "      <td>0.800387</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>0.872097</td>\n",
       "      <td>0.049068</td>\n",
       "      <td>0.795286</td>\n",
       "      <td>0.016967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  batch_size  epochs  trianing_loss mean  training_loss std  \\\n",
       "0         0.0001           8      12            0.911353           0.014751   \n",
       "\n",
       "   training_acc mean  training_acc std  validation_loss mean  \\\n",
       "0           0.800387          0.003726              0.872097   \n",
       "\n",
       "   validation_loss std  validaton_acc mean  validation_acc std  \n",
       "0             0.049068            0.795286            0.016967  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gridsearch = pd.DataFrame.from_records(gridsearch_records, columns=result_cols)\n",
    "# df_gridsearch.to_parquet(os.path.join(data_dir, \"ann_Net256_cv_results.parquet\"))\n",
    "df_gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "877df81c-a040-4781-9aec-0e79ecc83e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>trianing_loss mean</th>\n",
       "      <th>training_loss std</th>\n",
       "      <th>training_acc mean</th>\n",
       "      <th>training_acc std</th>\n",
       "      <th>validation_loss mean</th>\n",
       "      <th>validation_loss std</th>\n",
       "      <th>validaton_acc mean</th>\n",
       "      <th>validation_acc std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>0.232963</td>\n",
       "      <td>0.071239</td>\n",
       "      <td>0.928689</td>\n",
       "      <td>0.023166</td>\n",
       "      <td>0.671163</td>\n",
       "      <td>0.102071</td>\n",
       "      <td>0.832558</td>\n",
       "      <td>0.023664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>32</td>\n",
       "      <td>14</td>\n",
       "      <td>0.217851</td>\n",
       "      <td>0.047445</td>\n",
       "      <td>0.935106</td>\n",
       "      <td>0.013504</td>\n",
       "      <td>0.680141</td>\n",
       "      <td>0.128442</td>\n",
       "      <td>0.847695</td>\n",
       "      <td>0.019913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076482</td>\n",
       "      <td>0.014620</td>\n",
       "      <td>0.977050</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.620664</td>\n",
       "      <td>0.103051</td>\n",
       "      <td>0.856831</td>\n",
       "      <td>0.014711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>14</td>\n",
       "      <td>0.060025</td>\n",
       "      <td>0.022297</td>\n",
       "      <td>0.981709</td>\n",
       "      <td>0.007958</td>\n",
       "      <td>0.599271</td>\n",
       "      <td>0.070952</td>\n",
       "      <td>0.857891</td>\n",
       "      <td>0.021380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  batch_size  epochs  trianing_loss mean  training_loss std  \\\n",
       "0           0.05          32      12            0.232963           0.071239   \n",
       "1           0.05          32      14            0.217851           0.047445   \n",
       "2           0.01          32      12            0.076482           0.014620   \n",
       "3           0.01          32      14            0.060025           0.022297   \n",
       "\n",
       "   training_acc mean  training_acc std  validation_loss mean  \\\n",
       "0           0.928689          0.023166              0.671163   \n",
       "1           0.935106          0.013504              0.680141   \n",
       "2           0.977050          0.004677              0.620664   \n",
       "3           0.981709          0.007958              0.599271   \n",
       "\n",
       "   validation_loss std  validaton_acc mean  validation_acc std  \n",
       "0             0.102071            0.832558            0.023664  \n",
       "1             0.128442            0.847695            0.019913  \n",
       "2             0.103051            0.856831            0.014711  \n",
       "3             0.070952            0.857891            0.021380  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gridsearch = pd.DataFrame.from_records(gridsearch_records, columns=result_cols)\n",
    "df_gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "10b72d34-7b28-4881-99d1-9dffc1464cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNTest(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(256, 65),\n",
    "            nn.BatchNorm1d(65),\n",
    "            nn.ReLU(),\n",
    "            # nn.Linear(128, 39),\n",
    "            # nn.BatchNorm1d(39),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(65, 13),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "624540f1-920e-4870-9e60-80643b3a943e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.618468  Accuracy: 0.845234\n"
     ]
    }
   ],
   "source": [
    "# trained_model = torch.load(\"../models/kc_nn_Net256.pt\").to(device)\n",
    "learning_rate = 0.0005\n",
    "n_epochs = 4\n",
    "batch_size = 8\n",
    "chunk_print = 10\n",
    "torch.manual_seed(764)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_model = Net256(n_classes, 256, 52)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(test_model.parameters(), foreach=True, lr=learning_rate)\n",
    "\n",
    "# print(\"Begin training for Test\")\n",
    "for epoch in range(n_epochs):\n",
    "    # running_loss = 0.0\n",
    "    loss, accuracy = ms2_model.train_model(test_model, optimizer, loss_func, train_dataloader, device)\n",
    "train_loss = loss / len(train_dataloader.dataset)\n",
    "train_acc = accuracy / len(train_dataloader.dataset)\n",
    "print(f\"Loss: {train_loss:>5f}  Accuracy: {train_acc:>5f}\")\n",
    "# print(\"End training for test\")\n",
    "# torch.save(test_model, \"../models/kc_nn_Net256_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5bd1402-5439-4f94-a207-d419ee04a60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9815846410284108\n",
      "0.7802346570397112\n"
     ]
    }
   ],
   "source": [
    "y_label = df_data_test[\"Metadata_MoA\"].map(moa_dict).tolist()\n",
    "# loss_func = nn.CrossEntropyLoss()\n",
    "# print(\"Start testing\")\n",
    "test_loss, yhat_label = ms2_model.test_model(test_model, loss_func, test_dataloader, device)\n",
    "\n",
    "print(test_loss / len(test_dataloader.dataset))\n",
    "print(accuracy_score(y_label, yhat_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1005e9f4-957f-4fdf-8855-e90a7897fbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.32508356390447\n",
      "0.032490974729241874\n"
     ]
    }
   ],
   "source": [
    "trained_model = torch.load(\"../models/kc_nn_Net256.pt\").to(device)\n",
    "test_loss, yhat_label = ms2_model.test_model(trained_model, loss_func, test_dataloader, device)\n",
    "\n",
    "print(test_loss / len(test_dataloader.dataset))\n",
    "print(accuracy_score(y_label, yhat_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a450b567-e924-426f-a359-023415c62d09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
